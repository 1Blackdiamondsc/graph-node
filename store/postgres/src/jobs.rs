//! Jobs for database maintenance
use diesel::dsl::{exists, not};
use diesel::prelude::{
    BoolExpressionMethods, ExpressionMethods, JoinOnDsl, NullableExpressionMethods,
    OptionalExtension, QueryDsl, RunQueryDsl,
};
use diesel::{connection::SimpleConnection, sql_query, sql_types::Text, Connection, PgConnection};

use std::sync::Arc;
use std::time::{Duration, Instant};

use graph::components::store::StoreError;
use graph::prelude::{error, info, Logger, SubgraphDeploymentId};
use graph::util::jobs::{Job, Runner};

use crate::entities::{find_schema, Schema as DeploymentSchema};
use crate::Store;

pub fn register(runner: &mut Runner, store: Arc<Store>) {
    runner.register(
        Box::new(VacuumDeploymentsJob::new(store)),
        Duration::from_secs(60),
    );
}

/// A job that vacuums `subgraphs.subgraph_deployment`. With a large number
/// of subgraphs, the autovacuum daemon might not run often enough to keep
/// this table, which is _very_ write-heavy, from getting bloated. We
/// therefore set up a separate job that vacuums the table once a minute
struct VacuumDeploymentsJob {
    store: Arc<Store>,
}

impl VacuumDeploymentsJob {
    fn new(store: Arc<Store>) -> VacuumDeploymentsJob {
        VacuumDeploymentsJob { store }
    }

    fn vacuum(&self) -> Result<(), StoreError> {
        let conn = self.store.get_conn()?;
        conn.batch_execute("vacuum (analyze) subgraphs.subgraph_deployment")?;
        Ok(())
    }
}

impl Job for VacuumDeploymentsJob {
    fn name(&self) -> &str {
        "Vacuum subgraphs.subgraph_deployment"
    }

    fn run(&self, logger: &Logger) {
        if let Err(e) = self.vacuum() {
            error!(
                logger,
                "Vacuum of subgraphs.subgraph_deployment failed: {}", e
            );
        }
    }
}

struct RemoveDeploymentsJob {
    store: Arc<Store>,
}

impl RemoveDeploymentsJob {
    pub fn next_removable_deployment(
        conn: &PgConnection,
    ) -> Result<Option<DeploymentSchema>, StoreError> {
        use crate::entities::public::deployment_schemas as ds;
        use crate::entities::public::DeploymentSchemaVersion as DSV;
        use crate::metadata::subgraph as s;
        use crate::metadata::subgraph_deployment as d;
        use crate::metadata::subgraph_deployment_assignment as a;
        use crate::metadata::subgraph_version as v;

        let sid = d::table
            .inner_join(ds::table.on(d::id.eq(ds::subgraph)))
            .select(d::id)
            // The deployment must use relational storage
            .filter(ds::version.eq(DSV::Relational))
            // The deployment must not be assigned
            .filter(not(exists(a::table.select(a::id).filter(a::id.eq(d::id)))))
            // The deployment must not be the current or pending version
            // of any subgraph
            .filter(not(exists(
                s::table
                    .inner_join(v::table.on(s::id.eq(v::subgraph)))
                    .select(s::id)
                    .filter(d::id.eq(v::deployment))
                    .filter(
                        s::current_version
                            .eq(v::id.nullable())
                            .or(s::pending_version.eq(v::id.nullable())),
                    ),
            )))
            .first::<String>(conn)
            .optional()?;
        if let Some(sid) = sid {
            let deployment =
                SubgraphDeploymentId::new(sid).expect("Deployment ids in the database are valid");
            find_schema(conn, &deployment)
        } else {
            Ok(None)
        }
    }

    pub fn remove_deployment(
        conn: &PgConnection,
        deployment: &DeploymentSchema,
    ) -> Result<i32, StoreError> {
        use crate::entities::public::deployment_schemas as ds;
        use crate::metadata::subgraph_version as v;

        // The query in this file was generated by running 'make'
        // in the 'sql/' subdirectory
        // See also: ed42d219c6704a4aab57ce1ea66698e7
        // The query must be regenerated when the GraphQL schema changes
        const REMOVE_METADATA_QUERY: &str = include_str!("./sql/remove_metadata.sql");

        #[derive(QueryableByName)]
        struct MetadataCount {
            #[sql_type = "diesel::sql_types::Integer"]
            metadata_count: i32,
        }

        // Remove metadata
        let metadata_count: i32 = sql_query(REMOVE_METADATA_QUERY)
            .bind::<Text, _>(&deployment.subgraph)
            .get_result::<MetadataCount>(conn)?
            .metadata_count;

        // Drop the schema
        conn.batch_execute(&format!("drop schema {} cascade", deployment.name))?;

        // Remove from deployment_schemas
        diesel::delete(ds::table)
            .filter(ds::name.eq(&deployment.name))
            .execute(conn)?;

        // Remove any subgraph versions referring to this deployment
        diesel::delete(v::table)
            .filter(v::deployment.eq(&deployment.subgraph))
            .execute(conn)?;

        // FIXME: Must be relational storage
        // 0. Lookup schema name
        // 1. Remove metadata
        // 2. Remove schema
        // 3.   delete from deployment_schemas where subgraph = sid;
        // 4.   delete from subgraphs.subgraph_version where deployment = sid;

        Ok(metadata_count)
    }

    fn removal_loop(&self, logger: &Logger) -> Result<(), StoreError> {
        // To avoid holding up overall job execution, do this for no
        // more than 5 minutes
        const TIME_LIMIT: Duration = Duration::from_secs(300);

        let conn = self.store.get_conn()?;
        let start = Instant::now();
        while let Some(deployment) = Self::next_removable_deployment(&conn)? {
            info!(logger, "Remove unused deployment"; "deployment" => &deployment.subgraph);
            let res = conn.transaction(|| Self::remove_deployment(&conn, &deployment));
            match res {
                Err(e) => return Err(e),
                Ok(metadata_count) => {
                    info!(logger, "Removed unused deployment";
                          "deployment" => &deployment.subgraph,
                          "schema" => &deployment.name,
                          "metadata_count" => metadata_count);
                }
            }
            if start.elapsed() > TIME_LIMIT {
                return Ok(());
            }
        }
        Ok(())
    }
}

impl Job for RemoveDeploymentsJob {
    fn name(&self) -> &str {
        "Remove unused deployments"
    }

    fn run(&self, logger: &Logger) {
        if let Err(e) = self.removal_loop(logger) {
            error!(logger, "Remove unused deployments failed: {}", e);
        }
    }
}
